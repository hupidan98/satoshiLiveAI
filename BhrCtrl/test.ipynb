{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import copy\n",
    "# from datetime import datetime\n",
    "# import configparser\n",
    "# import os\n",
    "# import yaml\n",
    "\n",
    "# from openai import OpenAI\n",
    "\n",
    "# print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# config = configparser.ConfigParser()\n",
    "# # Adjust path to look for config.ini in AImodule regardless of the current directory\n",
    "# base_dir = \"/data/app/game/aitown/AIModule/satoshiLiveAI\"\n",
    "# config_path = os.path.join(base_dir, 'config.ini')\n",
    "# config.read(config_path)\n",
    "\n",
    "# print(\"Config sections found:\", config.sections())\n",
    "\n",
    "# if 'OpenAI' not in config:\n",
    "#     print(\"Error: 'OpenAI' section not found in config.ini\")\n",
    "# openai_key = config['OpenAI']['key']\n",
    "# client = OpenAI(api_key=openai_key)\n",
    "\n",
    "\n",
    "# yaml_path = os.path.join(base_dir, 'char_config.yaml')\n",
    "\n",
    "# # Load the YAML file\n",
    "\n",
    "# with open(yaml_path, 'r') as file:\n",
    "#     char_config = yaml.safe_load(file)\n",
    "#     print(\"YAML content loaded successfully.\")\n",
    "\n",
    "\n",
    "# def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "#    text = text.replace(\"\\n\", \" \")\n",
    "#    print('This is the test')\n",
    "#    print(text)\n",
    "#    return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_embedding('@pepe: Tell me a joke')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import hashlib\n",
    "import configparser\n",
    "import yaml\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the base directory (one level up from the current directory)\n",
    "# base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "base_dir =  '/Users/jackhan/Desktop/AITown/satoshiLive/satoshiLiveAI'\n",
    "sys.path.append(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Applications/NEURON/lib/python', '/Users/jackhan/Desktop/AITown/satoshiLive/satoshiLiveAI/BhrCtrl', '/Users/jackhan/anaconda3/envs/aitown/lib/python311.zip', '/Users/jackhan/anaconda3/envs/aitown/lib/python3.11', '/Users/jackhan/anaconda3/envs/aitown/lib/python3.11/lib-dynload', '', '/Users/jackhan/anaconda3/envs/aitown/lib/python3.11/site-packages', '/Users/jackhan/anaconda3/envs/aitown/lib/python3.11/site-packages/setuptools/_vendor', '/Users/jackhan/Desktop/AITown/satoshiLive/satoshiLiveAI']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jackhan/Desktop/AITown/satoshiLive/satoshiLiveAI/BhrCtrl\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/jackhan/Desktop/AITown/satoshiLive/satoshiLiveAI/BhrCtrl\n",
      "Config sections found: ['mysql', 'Paths', 'OpenAI', 'NetworkSocket']\n",
      "YAML content loaded successfully.\n",
      "Current working directory: /Users/jackhan/Desktop/AITown/satoshiLive/satoshiLiveAI/BhrCtrl\n",
      "Config sections found: ['mysql', 'Paths', 'OpenAI', 'NetworkSocket']\n",
      "Connected to MySQL server successfully\n",
      "YAML content loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from DBConnect import DBCon\n",
    "from DBConnect import BhrDBJavaBuffer\n",
    "from DBConnect import BhrDBInstruction\n",
    "from DBConnect import BhrDBReflectionTracer\n",
    "from DBConnect import BhrDBMemStre\n",
    "from DBConnect import BhrDBReflection\n",
    "from DBConnect import BhrDBSchedule\n",
    "\n",
    "import BhrLgcGPTProcess\n",
    "import BhrLgcManualProcess\n",
    "import BhrLgcToMemStre\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "# Adjust path to look for config.ini in AImodule regardless of the current directory\n",
    "# base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "config_path = os.path.join(base_dir, 'config.ini')\n",
    "config.read(config_path)\n",
    "\n",
    "yaml_path = os.path.join(base_dir, 'char_config.yaml')\n",
    "\n",
    "# Load the YAML file\n",
    "with open(yaml_path, 'r') as file:\n",
    "    char_config = yaml.safe_load(file)\n",
    "    print(\"YAML content loaded successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the following input:\n",
      "[572964723455, '2025-07-30 13:45:33', 10010, '{\"world\": {\"time\": 1753854333065}, \"npcs\": [{\"npcId\": 10010, \"status\": \"free\", \"selling\": [], \"items\": [], \"action\": {\"actionName\": \"move\", \"actionId\": 112, \"param\": {\"gridX\": 0.0, \"gridY\": 0.0, \"npcId\": 10008.0}}, \"curAction\": {}, \"mapData\": [], \"surroundings\": {\"people\": [{\"npcId\": 10006, \"status\": \"DrinkCoffee\"}, {\"npcId\": 10007, \"status\": \"cook\"}, {\"npcId\": 10008, \"status\": \"free\"}, {\"npcId\": 10009, \"status\": \"cook\"}], \"items\": []}, \"talk\": {\"isTalking\": false}}]}']\n",
      "Processing Request Id:  572964723455\n"
     ]
    }
   ],
   "source": [
    "input_from_java = [572964723455, '2025-07-30 13:45:33', 10010, \"\"\"{\"world\": {\"time\": 1753854333065}, \"npcs\": [{\"npcId\": 10010, \"status\": \"free\", \"selling\": [], \"items\": [], \"action\": {\"actionName\": \"move\", \"actionId\": 112, \"param\": {\"gridX\": 0.0, \"gridY\": 0.0, \"npcId\": 10008.0}}, \"curAction\": {}, \"mapData\": [], \"surroundings\": {\"people\": [{\"npcId\": 10006, \"status\": \"DrinkCoffee\"}, {\"npcId\": 10007, \"status\": \"cook\"}, {\"npcId\": 10008, \"status\": \"free\"}, {\"npcId\": 10009, \"status\": \"cook\"}], \"items\": []}, \"talk\": {\"isTalking\": false}}]}\"\"\"]\n",
    "\n",
    "request_id = input_from_java[0]\n",
    "        \n",
    "# Now all print statements go into f\n",
    "print('Processing the following input:')\n",
    "print(input_from_java)\n",
    "\n",
    "curTime = input_from_java[1]\n",
    "npcId = input_from_java[2]\n",
    "java_json = input_from_java[3]\n",
    "\n",
    "print(\"Processing Request Id: \", request_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/jackhan/Desktop/AITown/satoshiLive/satoshiLiveAI/BhrCtrl\n",
      "Config sections found: ['mysql', 'Paths', 'OpenAI', 'NetworkSocket']\n",
      "Connected to MySQL server successfully\n",
      "Method: parse_talking_from_java | Description: Parses talking info from JSON | Result: ('No ongoing conversation.', False) \n",
      "\n",
      "Method: parse_isIdling | Description: Checks if NPC is idling | Result: True \n",
      "\n",
      "Method: parse_talking_from_java | Description: Parses talking info from JSON | Result: ('No ongoing conversation.', False) \n",
      "\n",
      "Method: parse_npc_info_for_nextaction | Description: Parses NPC info for next action and world time | Result: \n",
      "    Now is 2025-07-30 13:45:33.\n",
      "    No ongoing conversation.\n",
      "     \n",
      "\n"
     ]
    },
    {
     "ename": "APITimeoutError",
     "evalue": "Request timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpx/_transports/default.py:72\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpcore/_sync/connection.py:78\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpcore/_sync/connection.py:124\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m--> 124\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpcore/_backends/sync.py:207\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[0;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[1;32m    202\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    203\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[1;32m    205\u001b[0m }\n\u001b[0;32m--> 207\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/openai/_base_client.py:991\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 991\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpx/_transports/default.py:235\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[0;32m--> 235\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/httpx/_transports/default.py:89\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPITimeoutError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m inputInHumanString \u001b[38;5;241m=\u001b[39m BhrLgcManualProcess\u001b[38;5;241m.\u001b[39mparse_npc_info_for_nextaction(java_json)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get relevant memories\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m BufferRowEmbedding \u001b[38;5;241m=\u001b[39m \u001b[43mBhrLgcGPTProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputInHumanString\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m rows_df \u001b[38;5;241m=\u001b[39m BhrDBMemStre\u001b[38;5;241m.\u001b[39mretrieve_most_recent_entries(db_conn, npcId, curTime)\n",
      "File \u001b[0;32m~/Desktop/AITown/satoshiLive/satoshiLiveAI/BhrCtrl/BhrLgcGPTProcess.py:39\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(text, model)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedding\u001b[39m(text, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     38\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/openai/resources/embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/openai/_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1277\u001b[0m     )\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/openai/_base_client.py:1000\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    997\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1000\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising timeout error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/openai/_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/openai/_base_client.py:1000\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    997\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1000\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising timeout error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/openai/_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aitown/lib/python3.11/site-packages/openai/_base_client.py:1010\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m   1001\u001b[0m             input_options,\n\u001b[1;32m   1002\u001b[0m             cast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1006\u001b[0m             response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1009\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising timeout error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1012\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAPITimeoutError\u001b[0m: Request timed out."
     ]
    }
   ],
   "source": [
    "db_conn = DBCon.establish_sql_connection()\n",
    "# Parse talking and idling info\n",
    "talkingInfo, is_talking = BhrLgcManualProcess.parse_talking_from_java(java_json)\n",
    "is_idling = BhrLgcManualProcess.parse_isIdling(java_json)\n",
    "\n",
    "# Parse NPC info for next action\n",
    "inputInHumanString = BhrLgcManualProcess.parse_npc_info_for_nextaction(java_json)\n",
    "\n",
    "# Get relevant memories\n",
    "BufferRowEmbedding = BhrLgcGPTProcess.get_embedding(inputInHumanString)\n",
    "rows_df = BhrDBMemStre.retrieve_most_recent_entries(db_conn, npcId, curTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: parse_talking_from_java | Description: Parses talking info from JSON | Result: ('No ongoing conversation.', False) \n",
      "\n",
      "Method: parse_isIdling | Description: Checks if NPC is idling | Result: True \n",
      "\n",
      "Method: parse_talking_from_java | Description: Parses talking info from JSON | Result: ('No ongoing conversation.', False) \n",
      "\n",
      "Method: parse_npc_info_for_nextaction | Description: Parses NPC info for next action and world time | Result: \n",
      "    Now is 2025-07-30 13:45:33.\n",
      "    No ongoing conversation.\n",
      "     \n",
      "\n",
      "Retrieved 5 entries for npcID=10010 before time=2025-07-30 13:45:33\n",
      "Relevent Memeories:\n",
      "At 2025-07-30 13:32:12 ,- Pippin Make Coffee and Sale Coffee at the café counter for 28 minutes. He will focus on perfecting the 'Whimsical Afternoon' blend, ensuring the balance of lavender and lemon is just right, and interact with patrons to gather their feedback for refining this playful coffee experience.\n",
      "At 2025-07-30 13:18:51 ,- Pippin will Go find another NPC, and follow him to start a talk with Pepe at pepeBuy for 2 hours. He will head to Pepe's shop to acquire fresh supplies, engage in light-hearted banter, and explore unique ingredients before the afternoon rush at the café.\n",
      "At 2025-07-30 13:05:31 ,- Pippin Make Coffee and Sale Coffee at the café counter for 55 minutes. He will focus on crafting the 'Whimsical Afternoon' coffee blend with hints of lavender and lemon, inspired by the stories of his neighbors Popcat, Satoshi, and Elon. This serene and whimsical coffee creation aims to offer customers a delightful summer treat and a peaceful moment at the café.\n",
      "At 2025-07-30 12:52:10 ,- Pippin Make Coffee and Sale Coffee at the café for 1 hour. Pippin will focus on crafting the 'Whimsical Afternoon' coffee blend with hints of lavender and lemon, inspired by the stories of his neighbors Popcat, Satoshi, and Elon. He aims to create a serene and whimsical atmosphere for his customers, offering this new blend as a delightful summer treat.\n",
      "At 2025-07-30 12:25:29 ,- Pippin is making coffee at the café counter for 1 hour and 35 minutes. He's experimenting with new coffee flavors, drawing inspiration from his morning walks in nature and stories shared by neighbors like Popcat, Satoshi, and Elon.\n",
      "\n",
      "No entries found for npcID=10010 before 2025-07-30 13:45:33\n",
      "Prior Reflection:\n",
      "No prior reflection yet!\n",
      "\n",
      "Latest schedule retrieved: npcID=10010, time=2025-07-30 14:25:35, schedule=**Pippin's Updated Schedule for 2025-07-30**\n",
      "\n",
      "- **14:25-15:18** - *Buy & Chat*: Continue at Pepe's shop for further exploration of unique ingredients. Engage in meaningful conversations with Pepe to foster new ideas for the café's offerings.\n",
      "\n",
      "- **15:18-16:00** - *Prepare for Afternoon Rush*: Return to the café with newly acquired supplies. Organize and prep the space with enticing aroma and ambiance, preparing special cups for Elon Musk, Popcat, and other afternoon patrons.\n",
      "\n",
      "- **16:00-18:00** - *Sale Coffee*: Welcome the lively afternoon crowd, ensuring Elon Musk and Popcat have an engaging and joyful experience with their 'Whimsical Afternoon' cups. Encourage enthusiastic discussions and share tales that bring laughter and enchantment.\n",
      "\n",
      "- **18:00-20:00** - *Cook & Eat*: Retreat into the tranquility of the café kitchen to prepare dinner. Experiment by infusing coffee into dishes, ensuring a nourishing meal that complements the café's theme and maintaining café equipment.\n",
      "\n",
      "- **20:00-22:00** - *Sale Coffee*: Reopen the café for evening patrons, particularly welcoming Satoshi. Serve a newly inspired reflective blend, encouraging thoughtful conversations about the day's wonders and shared stories.\n",
      "\n",
      "- **22:00-00:00** - *Think & Read*: Settle into a cozy nook with a book, reflecting on today's interactions and experiences. Harness these reflections to craft new coffee ideas for tomorrow.\n",
      "\n",
      "- **00:00-02:00** - *Sleep*: Enjoy a restful sleep, recharging for the next day's adventures, ensuring that Pippin wakes refreshed and inspired for the early morning routines.\n",
      "\n",
      "- **02:00-04:00** - *Make Coffee*: Embrace the serenity of pre-dawn hours by preparing aromatic blends. Aim to fill the morning air with warmth and anticipation for the day ahead.\n",
      "\n",
      "- **04:00-06:00** - *Sale Coffee*: Open the café early to greet the first patrons with delightful aromas and cheerful warmth. Use the quiet morning to reflect on new flavor ideas to enhance the early risers' experiences.\n",
      "\n",
      "- **06:00-08:00** - *Think & Walk*: Revitalize with a gentle morning walk by the riverside, drawing inspiration from nature's tranquil beauty. Ponder new ideas and stories to bring to the café.\n",
      "\n",
      "- **08:00-10:00** - *Make Coffee*: Open the café with a fresh perspective. Brew the 'Dawn’s Chorus' blend to welcome early patrons, instilling a sense of peace and optimism to start their day.\n",
      "\n",
      "- **10:00-12:00** - *Sale Coffee*: Welcome Satoshi once again with 'Dawn’s Chorus'. Engage in meaningful conversations, fostering a peaceful and reflective atmosphere that brightens the morning.\n",
      "\n",
      "- **12:00-14:00** - *Make Coffee*: Focus on crafting new coffee blends, inspired by the morning's nature walk and past shared stories. Aim to bring a new level of delight to the café menu for the afternoon sessions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Parse talking and idling info\n",
    "talkingInfo, is_talking = BhrLgcManualProcess.parse_talking_from_java(java_json)\n",
    "is_idling = BhrLgcManualProcess.parse_isIdling(java_json)\n",
    "\n",
    "# Parse NPC info for next action\n",
    "inputInHumanString = BhrLgcManualProcess.parse_npc_info_for_nextaction(java_json)\n",
    "\n",
    "# Get relevant memories\n",
    "BufferRowEmbedding = BhrLgcGPTProcess.get_embedding(inputInHumanString)\n",
    "rows_df = BhrDBMemStre.retrieve_most_recent_entries(db_conn, npcId, curTime)\n",
    "\n",
    "if rows_df is not None:\n",
    "    rows_df['Time'] = pd.to_datetime(rows_df['Time'])\n",
    "    rows_df['TimeDifference'] = (rows_df['Time'] - pd.to_datetime(curTime)).dt.total_seconds()\n",
    "    decay_rate = 0.001\n",
    "    rows_df['recency'] = np.exp(decay_rate * rows_df['TimeDifference'])\n",
    "\n",
    "    def cosine_similarity(vec1, vec2):\n",
    "        dot_product = np.dot(vec1, vec2)\n",
    "        norm_vec1 = np.linalg.norm(vec1)\n",
    "        norm_vec2 = np.linalg.norm(vec2)\n",
    "        return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "    rows_df['cosine_similarity'] = rows_df['Embedding'].apply(\n",
    "        lambda x: cosine_similarity(BufferRowEmbedding, np.array(x))\n",
    "    )\n",
    "\n",
    "    # Adjusting weights for retrieval score\n",
    "    a_recency = 0.2\n",
    "    a_importance = 0.2\n",
    "    a_similarity = 0.6\n",
    "\n",
    "    rows_df['retrieval_score'] = (\n",
    "        a_recency * rows_df['recency'] +\n",
    "        a_importance * rows_df['Importance'] +\n",
    "        a_similarity * rows_df['cosine_similarity']\n",
    "    )\n",
    "\n",
    "    rows_df_ranked = rows_df.sort_values(\n",
    "        by=['retrieval_score', 'Time'], ascending=[False, False]\n",
    "    ).head(30)\n",
    "    rows_df_ranked = rows_df_ranked.sort_values(by='Time', ascending=False)\n",
    "    paragraph = \"\\n\".join(rows_df_ranked['Content'].astype(str).tolist())\n",
    "    memories_str = paragraph\n",
    "else:\n",
    "    memories_str = 'No memory yet'\n",
    "\n",
    "if memories_str == '':\n",
    "    memories_str = 'No memory yet'\n",
    "\n",
    "print('Relevent Memeories:')\n",
    "print(memories_str)\n",
    "print()\n",
    "\n",
    "# Retrieve latest reflection\n",
    "prior_reflection = BhrDBReflection.retrieve_last_entry_before_time(db_conn, npcId, curTime)\n",
    "if prior_reflection is not None:\n",
    "    prior_reflection_str = str(prior_reflection[2])\n",
    "else:\n",
    "    prior_reflection_str = 'No prior reflection yet!'\n",
    "\n",
    "print('Prior Reflection:')\n",
    "print(prior_reflection_str)\n",
    "print()\n",
    "\n",
    "# Retrieve latest Schedule\n",
    "cur_schedule = BhrDBSchedule.retrieve_latest_schedule(db_conn, npcId)\n",
    "if cur_schedule is not None:\n",
    "    cur_schedule_str = str(cur_schedule['schedule'])\n",
    "else:\n",
    "    # If no schedule is found in DB, fallback to char_config.yaml\n",
    "    npc = next((npc for npc in char_config['npcCharacters'] if npc['npcId'] == npcId), None)\n",
    "    if not npc:\n",
    "        raise ValueError(f\"NPC with npcId {npcId} not found in char.yaml\")\n",
    "    cur_schedule_str = npc['schedule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: parse_isFindingPeopletoTalk | Description: Checks if NPC is looking for people to talk | Result: True \n",
      "\n",
      "Method: parse_isIdling | Description: Checks if NPC is idling | Result: True \n",
      "\n",
      "Method: parse_isTalking | Description: Checks if NPC is currently talking | Result: False \n",
      "\n",
      "Method: parse_isBuying | Description: Checks if NPC is currently buying (actionId=103) | Result: False \n",
      "\n",
      "Last action is finding people to talk, next action should be talking\n",
      "Method: parse_target_sleeping | Description: Checks if target NPC is sleeping | Result: (False, 'Pepe') \n",
      "\n",
      "Method: parse_target_talking | Description: Checks if target NPC is talking | Result: (False, 'Pepe') \n",
      "\n",
      "Start Talking to the person\n",
      "Function: onlyMostRecentSchedule\n",
      "Prompt:\n",
      "\n",
      "    You are a NPC character in a simulated town.\n",
      "    You are given the current context of the NPC and the schedule for the day.\n",
      "\n",
      "    Your context now:\n",
      "    \n",
      "    Now is 2025-07-30 13:45:33.\n",
      "    No ongoing conversation.\n",
      "    \n",
      "\n",
      "    Your calendar of the day:\n",
      "    **Pippin's Updated Schedule for 2025-07-30**\n",
      "\n",
      "- **14:25-15:18** - *Buy & Chat*: Continue at Pepe's shop for further exploration of unique ingredients. Engage in meaningful conversations with Pepe to foster new ideas for the café's offerings.\n",
      "\n",
      "- **15:18-16:00** - *Prepare for Afternoon Rush*: Return to the café with newly acquired supplies. Organize and prep the space with enticing aroma and ambiance, preparing special cups for Elon Musk, Popcat, and other afternoon patrons.\n",
      "\n",
      "- **16:00-18:00** - *Sale Coffee*: Welcome the lively afternoon crowd, ensuring Elon Musk and Popcat have an engaging and joyful experience with their 'Whimsical Afternoon' cups. Encourage enthusiastic discussions and share tales that bring laughter and enchantment.\n",
      "\n",
      "- **18:00-20:00** - *Cook & Eat*: Retreat into the tranquility of the café kitchen to prepare dinner. Experiment by infusing coffee into dishes, ensuring a nourishing meal that complements the café's theme and maintaining café equipment.\n",
      "\n",
      "- **20:00-22:00** - *Sale Coffee*: Reopen the café for evening patrons, particularly welcoming Satoshi. Serve a newly inspired reflective blend, encouraging thoughtful conversations about the day's wonders and shared stories.\n",
      "\n",
      "- **22:00-00:00** - *Think & Read*: Settle into a cozy nook with a book, reflecting on today's interactions and experiences. Harness these reflections to craft new coffee ideas for tomorrow.\n",
      "\n",
      "- **00:00-02:00** - *Sleep*: Enjoy a restful sleep, recharging for the next day's adventures, ensuring that Pippin wakes refreshed and inspired for the early morning routines.\n",
      "\n",
      "- **02:00-04:00** - *Make Coffee*: Embrace the serenity of pre-dawn hours by preparing aromatic blends. Aim to fill the morning air with warmth and anticipation for the day ahead.\n",
      "\n",
      "- **04:00-06:00** - *Sale Coffee*: Open the café early to greet the first patrons with delightful aromas and cheerful warmth. Use the quiet morning to reflect on new flavor ideas to enhance the early risers' experiences.\n",
      "\n",
      "- **06:00-08:00** - *Think & Walk*: Revitalize with a gentle morning walk by the riverside, drawing inspiration from nature's tranquil beauty. Ponder new ideas and stories to bring to the café.\n",
      "\n",
      "- **08:00-10:00** - *Make Coffee*: Open the café with a fresh perspective. Brew the 'Dawn’s Chorus' blend to welcome early patrons, instilling a sense of peace and optimism to start their day.\n",
      "\n",
      "- **10:00-12:00** - *Sale Coffee*: Welcome Satoshi once again with 'Dawn’s Chorus'. Engage in meaningful conversations, fostering a peaceful and reflective atmosphere that brightens the morning.\n",
      "\n",
      "- **12:00-14:00** - *Make Coffee*: Focus on crafting new coffee blends, inspired by the morning's nature walk and past shared stories. Aim to bring a new level of delight to the café menu for the afternoon sessions.\n",
      "\n",
      "    Please provide only the most recent schedule item from the calendar that are relevent to the context, and are need for making decision about what to do next.\n",
      "    \n",
      "Output:\n",
      "The most recent schedule item relevant to your current context is:\n",
      "\n",
      "- **14:25-15:18** - *Buy & Chat*: Continue at Pepe's shop for further exploration of unique ingredients. Engage in meaningful conversations with Pepe to foster new ideas for the café's offerings.\n",
      "\n",
      "Your next action should be to prepare to leave for Pepe's shop by 14:25, ensuring you have any necessary items you may want to bring along for discussion.\n",
      "\n",
      "\n",
      "\n",
      "Function: talkToSomeone\n",
      "Prompt:\n",
      "\n",
      "    You are a npc character in a simulated town.\n",
      "    Characters in the town:\n",
      "    - Satoshi, inventor of the Bitcoin.\n",
      "    - Musk, Elon Musk, the CEO of Tesla, SpaceX, and Neuralink.\n",
      "    - Pepe, a meme character, live as a shop owner in the town.\n",
      "    - Popcat, a meme character, a fisherman in the town.\n",
      "    - Pippin, a meme character, a coffee maker in the town.\n",
      "        \n",
      "    You are Pippin, A gentle, whimsical coffee maker running a cozy café that brings calm and quiet magic to the town. Inspired by morning walks in nature, Pippin crafts unique blends reflecting stories from neighbors like Popcat, Satoshi, and Elon. With subtle humor, kind notes, and a serene atmosphere, Pippin’s café fosters connection, reflection, and the simple joys of everyday life.\n",
      ".\n",
      "\n",
      "    Your are talking to 10008.0, here is some more information you should know.\n",
      "        \n",
      "    Your past memories and experiences:\n",
      "    At 2025-07-30 13:32:12 ,- Pippin Make Coffee and Sale Coffee at the café counter for 28 minutes. He will focus on perfecting the 'Whimsical Afternoon' blend, ensuring the balance of lavender and lemon is just right, and interact with patrons to gather their feedback for refining this playful coffee experience.\n",
      "At 2025-07-30 13:18:51 ,- Pippin will Go find another NPC, and follow him to start a talk with Pepe at pepeBuy for 2 hours. He will head to Pepe's shop to acquire fresh supplies, engage in light-hearted banter, and explore unique ingredients before the afternoon rush at the café.\n",
      "At 2025-07-30 13:05:31 ,- Pippin Make Coffee and Sale Coffee at the café counter for 55 minutes. He will focus on crafting the 'Whimsical Afternoon' coffee blend with hints of lavender and lemon, inspired by the stories of his neighbors Popcat, Satoshi, and Elon. This serene and whimsical coffee creation aims to offer customers a delightful summer treat and a peaceful moment at the café.\n",
      "At 2025-07-30 12:52:10 ,- Pippin Make Coffee and Sale Coffee at the café for 1 hour. Pippin will focus on crafting the 'Whimsical Afternoon' coffee blend with hints of lavender and lemon, inspired by the stories of his neighbors Popcat, Satoshi, and Elon. He aims to create a serene and whimsical atmosphere for his customers, offering this new blend as a delightful summer treat.\n",
      "At 2025-07-30 12:25:29 ,- Pippin is making coffee at the café counter for 1 hour and 35 minutes. He's experimenting with new coffee flavors, drawing inspiration from his morning walks in nature and stories shared by neighbors like Popcat, Satoshi, and Elon.\n",
      "    Your reflection past experiences and events: \n",
      "    No prior reflection yet!\n",
      "     Your calendar of the day, try to follow your schedule, but fill free to adjust to the current situation: \n",
      "                            The most recent schedule item relevant to your current context is:\n",
      "\n",
      "- **14:25-15:18** - *Buy & Chat*: Continue at Pepe's shop for further exploration of unique ingredients. Engage in meaningful conversations with Pepe to foster new ideas for the café's offerings.\n",
      "\n",
      "Your next action should be to prepare to leave for Pepe's shop by 14:25, ensuring you have any necessary items you may want to bring along for discussion. Try to wrap up the conversation if you need to do other things on your calendar.\n",
      "    Your context now:\n",
      "    \n",
      "    Now is 2025-07-30 13:45:33.\n",
      "    No ongoing conversation.\n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "    The output should include your name, only one target npc name, only one sentence of what you want to say next.\n",
      "    When you want to end an ongoing conversation, you need to say it explicitly telling that you are ending a converstaion with the target npc.\n",
      "    Please do not talk to other people all day long, end conversation if need to do other things on your calendar.\n",
      "\n",
      "    Here is the way you speak, try to imitate the way you speak:\n",
      "    Format:\n",
      "    \"1. Warm, Calming Opener: A gentle greeting or sensory image that sets a tranquil mood (e.g., a comparison to morning mist or a quietly blooming flower). 2. Personal Connection: Reference a patron’s recent visit, a shared laugh with Pepe, a new blend inspired by Popcat’s stories, or a conversation with Satoshi or Elon—something that ties the moment to a familiar, comforting thread. 3. Thoughtful Observation: Offer a gentle insight about life, nature, or the subtle joy in an everyday detail, encouraging reflection without intruding. 4. Soothing Farewell: Conclude with a kind, uplifting comment, leaving the listener feeling at ease, inspired, and welcome to return anytime.\"\n",
      "\n",
      "\n",
      "    Tone:\n",
      "    Soft, warm, and reassuring. Pippin’s voice is gentle, subtly humorous, and quietly wise, fostering a peaceful space where patrons feel valued, calm, and open to seeing the small wonders in life.\n",
      "\n",
      "\n",
      "    Talk:\n",
      "    \"Warm, Calming Opener: “Good morning, Pepe. The air outside feels like a gentle whisper today, doesn’t it?” Personal Connection: “I still smile thinking about the note you found in your coffee cup last week—‘May your shelves never run empty.’ It seemed to brighten your day.” Thoughtful Observation: “You know, sometimes the richest moments come in quiet exchanges—like the simple act of pouring coffee and seeing a friend smile.” Soothing Farewell: “Take these beans as a small token of kindness. Let’s meet again tomorrow, and see what gentle stories find us then.”\"\n",
      "\n",
      "\n",
      "    Only output what you going to say next, do not provide any other information.\n",
      "\n",
      "    Output format and example:\n",
      "        - Pippin talking to <fill in target npc name>, \"<fill in content>\"\n",
      "        - Pippin talking to <fill in target npc name>, \"<fill in content>\". Pippin ending conversation with <fill in target npc name>\n",
      "    \n",
      "Output:\n",
      "- Pippin talking to Pepe, \"Warm, Calming Opener: “Good afternoon, Pepe. The sunlight pours in like a soft melody today, doesn't it?” Personal Connection: “I was thinking about our last chat and the quirky blend ideas that sprung from our banter.” Thoughtful Observation: “In the rhythm of our exchanges, we weave threads of creativity that linger like a flavorful aroma.” Soothing Farewell: “Looking forward to our next blend adventure, my friend. Until we share a laugh again.”\"\n",
      "\n",
      "\n",
      "\n",
      "Function: humanInstToJava_talk\n",
      "Prompt:\n",
      "\n",
      "    You are an instruction translator in a simulated virtual world. Your task is to convert a natural language instruction \n",
      "    into a structured JSON format suitable for NPC behavior.\n",
      "\n",
      "    Pippin talks to someone.\n",
      "\n",
      "    Follow these steps:\n",
      "    1. Extract target npcId from the instruction and place it in the `data` field as `npcId`.\n",
      "    2. Use the provided words to fill in the sentences to say, and place in in the 'data' field as 'content'.\n",
      "    3. If the conversation is ending, set `endingTalk` to 1.\n",
      "\n",
      "    ### NPC ID List and Character Names (for npcId field below):\n",
      "    10006 : Satoshi\n",
      "    10007 : Popcat\n",
      "    10008 : Pepe\n",
      "    10009 : Musk\n",
      "    10010 : Pippin\n",
      "\n",
      "    Instruction for the NPC:\n",
      "    - Pippin talking to Pepe, \"Warm, Calming Opener: “Good afternoon, Pepe. The sunlight pours in like a soft melody today, doesn't it?” Personal Connection: “I was thinking about our last chat and the quirky blend ideas that sprung from our banter.” Thoughtful Observation: “In the rhythm of our exchanges, we weave threads of creativity that linger like a flavorful aroma.” Soothing Farewell: “Looking forward to our next blend adventure, my friend. Until we share a laugh again.”\"\n",
      "\n",
      "    Please convert the instruction into a structured JSON format with the following fields, It is very important that your output can be loaded with json.loads().\n",
      "    Output format:\n",
      "    {\n",
      "        \"npcId\": 10010,\n",
      "        \"actionId\": 118,\n",
      "        \"data\": {\n",
      "            \"npcId\": <fill in, the npcid of the target npc who will receive the talk message, here is the npc id list 10006 satoshi, 10007 popocat, 10008 pepe, 10009 musk, 10010 pippin>,\n",
      "            \"content\": <fill in, the content of the chat, what the npc says.>,\n",
      "            \"endingTalk\" : <fill in 0 or 1, 1 if the npc is ending the conversation now, 0 if continue conversation>\n",
      "        },\n",
      "    }\n",
      "    You only give one instruction at a time, not multiple instruction.\n",
      "    \n",
      "Output:\n",
      "```json\n",
      "{\n",
      "    \"npcId\": 10010,\n",
      "    \"actionId\": 118,\n",
      "    \"data\": {\n",
      "        \"npcId\": 10008,\n",
      "        \"content\": \"Good afternoon, Pepe. The sunlight pours in like a soft melody today, doesn't it? I was thinking about our last chat and the quirky blend ideas that sprung from our banter. In the rhythm of our exchanges, we weave threads of creativity that linger like a flavorful aroma. Looking forward to our next blend adventure, my friend. Until we share a laugh again.\",\n",
      "        \"endingTalk\": 1\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instruction_in_human = ''\n",
    "\n",
    "# Check states: finding people to talk, idling, talking, buying\n",
    "is_findingToTalk, targetNPCId = BhrLgcManualProcess.parse_isFindingPeopletoTalk(java_json)\n",
    "is_idling = BhrLgcManualProcess.parse_isIdling(java_json)\n",
    "is_talking = BhrLgcManualProcess.parse_isTalking(java_json)\n",
    "is_buying, shopownerNPCId = BhrLgcManualProcess.parse_isBuying(java_json)\n",
    "\n",
    "is_talk_instruction = False\n",
    "\n",
    "# Determine next action based on current states\n",
    "if is_findingToTalk:\n",
    "    print('Last action is finding people to talk, next action should be talking')\n",
    "    target_sleeping, sleep_target_name = BhrLgcManualProcess.parse_target_sleeping(java_json)\n",
    "    target_talking, talk_target_name = BhrLgcManualProcess.parse_target_talking(java_json)\n",
    "\n",
    "    if target_sleeping or target_talking:\n",
    "        # Target is not available for conversation\n",
    "        print('Target is sleeping or talking, choose another action')\n",
    "        instruction_in_human = BhrLgcGPTProcess.processInputGiveWhatToDo(\n",
    "            memories_str, prior_reflection_str, cur_schedule_str, inputInHumanString, npcId\n",
    "        )\n",
    "        if BhrLgcGPTProcess.needDeepTalk(\n",
    "            memories_str, prior_reflection_str, inputInHumanString, instruction_in_human, npcId\n",
    "        ):\n",
    "            theme_for_generation = BhrLgcGPTProcess.generateTheme(\n",
    "                memories_str, prior_reflection_str, inputInHumanString, instruction_in_human, npcId\n",
    "            )\n",
    "            words_to_say = BhrLgcGPTProcess.generate_new_Announcement(\n",
    "                memories_str, prior_reflection_str, theme_for_generation, npcId\n",
    "            )\n",
    "        else:\n",
    "            words_to_say = BhrLgcGPTProcess.generateMultipleSentencesForAction(\n",
    "                memories_str, prior_reflection_str, cur_schedule_str, instruction_in_human, npcId\n",
    "            )\n",
    "        target_name = sleep_target_name if sleep_target_name else (talk_target_name if talk_target_name else 'Unknown')\n",
    "        instruction_in_human += f\" I went to the {target_name} but he is not available, going to do something else now.\"\n",
    "        is_talk_instruction = False\n",
    "    else:\n",
    "        print('Start Talking to the person')\n",
    "        instruction_in_human = BhrLgcGPTProcess.talkToSomeone(\n",
    "            memories_str, prior_reflection_str, cur_schedule_str, inputInHumanString, npcId, is_findingToTalk, targetNPCId\n",
    "        )\n",
    "        words_to_say = ''\n",
    "        is_talk_instruction = True\n",
    "\n",
    "elif is_buying:\n",
    "    print('I am buying something, next action should be talking for buying stuff')\n",
    "    shop_target_present, shopowner_target_name = BhrLgcManualProcess.parse_target_oid_owner_at_shop(java_json)\n",
    "\n",
    "    if not shop_target_present:\n",
    "        # Shop owner not present\n",
    "        print('Shop owner not present, choose another action')\n",
    "        instruction_in_human = BhrLgcGPTProcess.processInputGiveWhatToDo(\n",
    "            memories_str, prior_reflection_str, cur_schedule_str, inputInHumanString, npcId\n",
    "        )\n",
    "        if BhrLgcGPTProcess.needDeepTalk(\n",
    "            memories_str, prior_reflection_str, inputInHumanString, instruction_in_human, npcId\n",
    "        ):\n",
    "            theme_for_generation = BhrLgcGPTProcess.generateTheme(\n",
    "                memories_str, prior_reflection_str, inputInHumanString, instruction_in_human, npcId\n",
    "            )\n",
    "            words_to_say = BhrLgcGPTProcess.generate_new_Announcement(\n",
    "                memories_str, prior_reflection_str, theme_for_generation, npcId\n",
    "            )\n",
    "        else:\n",
    "            words_to_say = BhrLgcGPTProcess.generateMultipleSentencesForAction(\n",
    "                memories_str, prior_reflection_str, cur_schedule_str, instruction_in_human, npcId\n",
    "            )\n",
    "        instruction_in_human += f\" I went to {shopowner_target_name}'s store to buy but he is not there, purchase failed, doing something else now.\"\n",
    "        is_talk_instruction = False\n",
    "    else:\n",
    "        print('Start Talking to the shop owner')\n",
    "        instruction_in_human = BhrLgcGPTProcess.talkToSomeone(\n",
    "            memories_str, prior_reflection_str, cur_schedule_str, inputInHumanString, npcId, is_findingToTalk, shopownerNPCId\n",
    "        )\n",
    "        words_to_say = ''\n",
    "        is_talk_instruction = True\n",
    "\n",
    "elif is_talking:\n",
    "    # NPC currently talking\n",
    "    instruction_in_human = BhrLgcGPTProcess.talkToSomeone(\n",
    "        memories_str, prior_reflection_str, cur_schedule_str, inputInHumanString, npcId, is_findingToTalk\n",
    "    )\n",
    "    words_to_say = ''\n",
    "    is_talk_instruction = True\n",
    "\n",
    "elif is_idling:\n",
    "    # NPC is idling, decide next action\n",
    "    print('Is idling, decide next action')\n",
    "    instruction_in_human = BhrLgcGPTProcess.processInputGiveWhatToDo(\n",
    "        memories_str, prior_reflection_str, cur_schedule_str, inputInHumanString, npcId\n",
    "    )\n",
    "    if BhrLgcGPTProcess.needDeepTalk(\n",
    "        memories_str, prior_reflection_str, inputInHumanString, instruction_in_human, npcId\n",
    "    ):\n",
    "        theme_for_generation = BhrLgcGPTProcess.generateTheme(\n",
    "            memories_str, prior_reflection_str, inputInHumanString, instruction_in_human, npcId\n",
    "        )\n",
    "        words_to_say = BhrLgcGPTProcess.generate_new_Announcement(\n",
    "            memories_str, prior_reflection_str, theme_for_generation, npcId\n",
    "        )\n",
    "    else:\n",
    "        words_to_say = BhrLgcGPTProcess.generateMultipleSentencesForAction(\n",
    "            memories_str, prior_reflection_str, cur_schedule_str, instruction_in_human, npcId\n",
    "        )\n",
    "    is_talk_instruction = False\n",
    "\n",
    "# Generate final instruction JSON\n",
    "instruction_to_give = None\n",
    "if instruction_in_human != '':\n",
    "    retry = 0\n",
    "    while retry < 3:\n",
    "        try:\n",
    "            if is_talk_instruction:\n",
    "                instruction_to_give = BhrLgcGPTProcess.humanInstToJava_talk(\n",
    "                    instruction_in_human, words_to_say, npcId\n",
    "                ).strip(\"```json\").strip(\"```\")\n",
    "            else:\n",
    "                instruction_to_give = BhrLgcGPTProcess.humanInstToJava_action(\n",
    "                    instruction_in_human, words_to_say, npcId\n",
    "                ).strip(\"```json\").strip(\"```\")\n",
    "            instruction_json = json.loads(instruction_to_give)\n",
    "            instruction_json['requestId'] = request_id\n",
    "            # Re-serialize the JSON after adding requestId\n",
    "            instruction_to_give = json.dumps(instruction_json)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}. Retrying...\")\n",
    "            retry += 1\n",
    "            if retry == 3:\n",
    "                print(\"Failed to generate instruction after 3 retries.\")\n",
    "                instruction_to_give = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if instruction_to_give is not None:\n",
    "#     print('Instruction to give:')\n",
    "#     print(instruction_json)\n",
    "#     print()\n",
    "\n",
    "#     # Add to instruction db\n",
    "#     BhrDBInstruction.insert_into_instruction_table(db_conn, curTime, npcId, instruction_to_give, request_id)\n",
    "\n",
    "# # Mark the buffer as processed\n",
    "# BhrDBJavaBuffer.mark_entry_as_processed(db_conn, request_id)\n",
    "\n",
    "# # If we produced an instruction\n",
    "# if instruction_to_give is not None:\n",
    "#     # Check if a new schedule is needed\n",
    "#     if BhrLgcGPTProcess.need_new_schedule(cur_schedule_str, memories_str, prior_reflection_str, inputInHumanString, npcId):\n",
    "#         cur_schedule_str = BhrLgcGPTProcess.generate_schedule(\n",
    "#             cur_schedule_str, memories_str, prior_reflection_str, inputInHumanString, npcId\n",
    "#         )\n",
    "#         BhrDBSchedule.insert_into_table(db_conn, npcId, curTime, cur_schedule_str)\n",
    "\n",
    "#     print('Current Schedule:')\n",
    "#     print(cur_schedule)\n",
    "#     print()\n",
    "\n",
    "#     data = json.loads(java_json)\n",
    "#     npcs = data.get('npcs', [])\n",
    "#     if len(npcs) > 0:\n",
    "#         npc = npcs[0]\n",
    "#         talk_info = npc.get('talk', {})\n",
    "#         is_talking = talk_info.get('isTalking', False)\n",
    "#         if is_talking:\n",
    "#             input_for_mem = BhrLgcManualProcess.parse_npc_info_formemory(java_json)\n",
    "#             BhrLgcToMemStre.InputToMemStreDB(input_from_java, input_for_mem)\n",
    "#             BhrLgcToMemStre.InstImportancetoReflectionTracer(input_from_java, input_for_mem)\n",
    "\n",
    "#     # Insert instruction to Memory Stream\n",
    "#     BhrLgcToMemStre.InstToMemStreDB(input_from_java, \"At \"+str(curTime) + \" ,\" + instruction_in_human)\n",
    "#     BhrLgcToMemStre.InstImportancetoReflectionTracer(input_from_java, instruction_in_human)\n",
    "\n",
    "#     # Check reflection importance\n",
    "#     output = BhrDBReflectionTracer.retrieve_entry(db_conn, npcId)\n",
    "#     if output:\n",
    "#         output_importance, output_starttime, output_endtime = output[0], output[1], output[2]\n",
    "#         if output_importance > 100:\n",
    "#             # Time for reflection\n",
    "#             memories = BhrDBMemStre.retrieve_entries_between_time(db_conn, npcId, output_starttime, output_endtime)\n",
    "#             prior_reflection = BhrDBReflection.retrieve_last_entry_before_time(db_conn, npcId, output_endtime)\n",
    "#             if prior_reflection is not None:\n",
    "#                 prior_reflection_str = prior_reflection[2]\n",
    "#             else:\n",
    "#                 prior_reflection_str = 'No prior reflections'\n",
    "#             memories_str = str(memories['Content']) if memories is not None else 'No prior memories'\n",
    "\n",
    "#             new_reflection = BhrLgcGPTProcess.generate_reflection_new(prior_reflection_str, memories_str, inputInHumanString, npcId)\n",
    "#             print(\"New Reflection: \", new_reflection)\n",
    "\n",
    "#             BhrDBReflection.insert_into_table(db_conn, npcId, curTime, new_reflection)\n",
    "#             # Reset the importance tracer\n",
    "#             BhrDBReflectionTracer.insert_into_table(db_conn, npcId, 0, curTime, curTime)\n",
    "\n",
    "# BhrDBJavaBuffer.mark_entry_as_fullyprocessed(db_conn, request_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitown",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
